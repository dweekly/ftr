name: Publish to APT Repository on R2

# This workflow publishes Debian packages to an APT repository hosted on Cloudflare R2.
# To optimize performance, it only syncs metadata files (dists/) and uploads new .deb files,
# avoiding the need to download all existing .deb packages.

on:
  release:
    types: [published] # Triggers when a new release is published
  workflow_dispatch: # allow manual triggering in GitHub UI

jobs:
  build_and_publish_apt:
    runs-on: ubuntu-latest
    permissions:
      contents: read # To checkout the repository
      id-token: write # If you were to use Cloudflare OIDC for rclone (more advanced)
    
    env:
      R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
      APT_REPO_PREFIX: "" # Optional: if your repo is in a subdirectory within the R2 bucket root e.g. "apt"
      APT_DISTRIBUTION: "stable"
      APT_COMPONENT: "main"
      APT_REPO_NAME: "ftr-repo" # Name of the aptly local repo
      GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
      # For rclone S3 provider
      RCLONE_S3_PROVIDER: "Cloudflare"
      RCLONE_S3_ACCESS_KEY_ID: ${{ secrets.RCLONE_ACCESS_KEY_ID }}
      RCLONE_S3_SECRET_ACCESS_KEY: ${{ secrets.RCLONE_SECRET_ACCESS_KEY }}
      RCLONE_S3_ENDPOINT: "https://${{ secrets.RCLONE_ACCOUNT_ID }}.r2.cloudflarestorage.com"
      RCLONE_S3_REGION: "auto" # Or your specific region, e.g., "wnam"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Install cargo-deb
        run: cargo install cargo-deb

      - name: Install aptly
        run: |
          sudo apt-get update

          # Ensure dependencies for adding external repositories are present
          sudo apt-get install -y gpg wget ca-certificates jq

          # Download aptly's GPG key directly and store it in the recommended location
          wget -qO - https://www.aptly.info/pubkey.txt | sudo gpg --dearmor -o /usr/share/keyrings/aptly-archive-keyring.gpg

          # Add aptly's repository, referencing the GPG key
          echo "deb [signed-by=/usr/share/keyrings/aptly-archive-keyring.gpg] https://repo.aptly.info/ stable main" | sudo tee /etc/apt/sources.list.d/aptly.list

          # Update package list and install aptly
          sudo apt-get update
          sudo apt-get install -y aptly

      - name: Install rclone
        run: |
          sudo apt-get update
          sudo apt-get install -y rclone
      
      - name: Configure rclone (using env vars)
        run: |
          rclone version # Verifies rclone can see S3 env vars (RCLONE_S3_*)
          # No explicit rclone config file needed when using env vars for S3 provider

      - name: Import GPG Key
        uses: crazy-max/ghaction-import-gpg@v6
        with:
          gpg_private_key: ${{ secrets.GPG_PRIVATE_KEY }}
          passphrase: ${{ secrets.GPG_PASSPHRASE }}
          # GPG User ID will be automatically trusted.

      - name: Prepare aptly directories and data
        run: |
          mkdir -p ~/.aptly/db ~/.aptly/public
          echo "Downloading existing aptly database (if any)..."
          rclone sync ":s3:${R2_BUCKET_NAME}/_aptly_db/" ~/.aptly/db/ --create-empty-src-dirs || echo "No existing aptly DB found or error syncing, proceeding..."
          
          # Only download metadata files, not the actual .deb packages
          echo "Downloading existing repository metadata..."
          mkdir -p ~/.aptly/public/dists ~/.aptly/public/pool
          
          # Download only the metadata structure (dists directory)
          rclone sync ":s3:${R2_BUCKET_NAME}/dists/" ~/.aptly/public/dists/ --create-empty-src-dirs || echo "No existing dists found"
          
          # Ensure aptly config exists, create a basic one if not
          if [ ! -f ~/.aptly.conf ]; then
            echo '{ "rootDir": "'$HOME'/.aptly" }' > ~/.aptly.conf
            echo "Created default aptly.conf"
          fi
          aptly version # Verify aptly is working

      - name: Build .deb package
        run: |
          cargo deb --output target/debian/
          # Find the .deb file (adjust if your naming/path is different)
          DEB_FILE=$(find target/debian -name "*.deb" -type f | head -n 1)
          if [ -z "$DEB_FILE" ]; then
            echo "Error: .deb file not found!"
            exit 1
          fi
          echo "DEB_FILE=$DEB_FILE" >> $GITHUB_ENV
          
          # Extract package name for pool path
          CARGO_PKG_NAME=$(cargo metadata --no-deps --format-version 1 | jq -r '.packages[0].name')
          echo "CARGO_PKG_NAME=$CARGO_PKG_NAME" >> $GITHUB_ENV

      - name: Add package to aptly and publish
        env:
          APTLY_GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }} # Pass GPG passphrase to aptly
        run: |
          # Create local repo if it doesn't exist
          if ! aptly repo show -with-packages "${APT_REPO_NAME}"; then
            echo "Creating aptly local repo: ${APT_REPO_NAME}"
            aptly repo create -distribution="${APT_DISTRIBUTION}" -component="${APT_COMPONENT}" "${APT_REPO_NAME}"
          else
            echo "Aptly local repo ${APT_REPO_NAME} already exists."
          fi

          echo "Adding package ${{ env.DEB_FILE }} to ${APT_REPO_NAME}..."
          aptly repo add "${APT_REPO_NAME}" "${{ env.DEB_FILE }}"

          SNAPSHOT_NAME="${APT_REPO_NAME}-$(date +%s)-${GITHUB_SHA::7}"
          echo "Creating snapshot: ${SNAPSHOT_NAME}"
          aptly snapshot create "${SNAPSHOT_NAME}" from repo "${APT_REPO_NAME}"

          echo "Publishing snapshot..."
          # If publishing for the first time to this prefix/distribution:
          if ! aptly publish list | grep -q "${APT_DISTRIBUTION} .*${APT_REPO_PREFIX}"; then
             echo "Publishing new snapshot ${SNAPSHOT_NAME} for ${APT_DISTRIBUTION} at prefix '${APT_REPO_PREFIX}'"
             aptly publish snapshot -gpg-key="${GPG_KEY_ID}" -distribution="${APT_DISTRIBUTION}" -component="${APT_COMPONENT}" "${SNAPSHOT_NAME}" "${APT_REPO_PREFIX}"
          else
             echo "Switching existing publication for ${APT_DISTRIBUTION} at prefix '${APT_REPO_PREFIX}' to snapshot ${SNAPSHOT_NAME}"
             aptly publish switch -gpg-key="${GPG_KEY_ID}" -component="${APT_COMPONENT}" "${APT_DISTRIBUTION}" "${APT_REPO_PREFIX}" "${SNAPSHOT_NAME}"
          fi
          
          # Cleanup old snapshots (optional, keep last 5 for example)
          aptly snapshot list -sort=time | awk 'NR>5 {print $1}' | xargs -r aptly snapshot drop

      - name: Upload APT repository files to R2
        run: |
          echo "Uploading new .deb package to R2..."
          # Upload the new .deb file
          DEB_FILENAME=$(basename "${{ env.DEB_FILE }}")
          POOL_PATH="pool/${APT_COMPONENT}/${DEB_FILENAME:0:1}/${CARGO_PKG_NAME}/"
          rclone mkdir ":s3:${R2_BUCKET_NAME}/${POOL_PATH}"
          rclone copy "${{ env.DEB_FILE }}" ":s3:${R2_BUCKET_NAME}/${POOL_PATH}" --progress
          
          echo "Uploading updated metadata to R2..."
          # Only sync the dists directory (metadata)
          rclone sync ~/.aptly/public/dists/ ":s3:${R2_BUCKET_NAME}/dists/" --create-empty-src-dirs --progress
          
          # Also ensure the GPG key exists
          if [ ! -f ~/.aptly/public/networkweather.gpg.key ]; then
            echo "Exporting GPG public key..."
            gpg --armor --export "${GPG_KEY_ID}" > ~/.aptly/public/networkweather.gpg.key
            rclone copy ~/.aptly/public/networkweather.gpg.key ":s3:${R2_BUCKET_NAME}/" --progress
          fi

      - name: Sync aptly database back to R2
        run: |
          echo "Syncing ~/.aptly/db/ to R2 bucket ${R2_BUCKET_NAME}/_aptly_db/..."
          rclone sync ~/.aptly/db/ ":s3:${R2_BUCKET_NAME}/_aptly_db/" --create-empty-src-dirs --progress --verbose